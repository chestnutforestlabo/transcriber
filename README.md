# Transcribers ğŸ“ğŸ™ï¸

A toolkit that **automatically transcribes multiâ€‘speaker meetings** with  
**Whisper v3** (ASR) + **Pyannote** (speaker diarization) and lets you review  
the result in a React frontâ€‘end with waveformâ€‘synchronised captions.

Project structure
â”œâ”€ backend/ # Inference scripts & model wrappers
â”œâ”€ frontend/ # Vite + React web app
â”œâ”€ audios/num_speakers=N/ # Input audio files (N = max number of speakers)
â””â”€ output/ # JSON result (created after inference)

---

## 0. Prerequisites

| Requirement           | Recommended | Notes                                   |
|-----------------------|-------------|-----------------------------------------|
| Python                | 3.9+        | We use Poetry for dependency handling   |
| CUDAâ€‘enabled GPU      | optional    | CPU works but will be slow              |
| Docker / DockerÂ Compose| 23.x / v2  | For launching the frontâ€‘end container   |
| HuggingÂ Face token    | required    | *Read* scope is enough                  |

---

## 1.Â Backend setup

```bash
# Install Python deps + download models
bash backend_setup_1.sh

# Log in to HuggingÂ Face CLI (paste your token)
bash backend_setup_2.sh
```

During backend_setup_2.sh you will see
Please log in to Hugging Face using the CLIâ€¦ â€” simply paste your token.

## 2. Add your audio
```bash
# exsample
audios/
â”œâ”€ num_speakers=1/
â”œâ”€ num_speakers=2/
â”‚   â”œâ”€ sample1.wav
â”‚   â””â”€ sample2.wav
â””â”€ num_speakers=3/
```

Put .wav files (16Â kHz recommended) under the folder that encodes the
maximum number of different speakers in the recording, e.g.
audios/num_speakers=2/ for a twoâ€‘speaker conversation.

## 3. Run transcription
Results are saved to output/<file>.json and
frontend/public/transcripts/<file>.json.
The original audio is also copied to frontend/public/audios/, and
index.json is autoâ€‘updated for the frontâ€‘end.

```bash
bash backend_transcriber.sh
```

## 4. Start the frontâ€‘end
Open http://localhost:5173 in your browser.
You should see the waveform, speakerâ€‘coloured captions, and you can seek by
clicking either the text or the waveform.

```bash
bash frontend_activate.sh
```

<!-- ## How to activate local server?

Install nvm:

```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
source ~/.bashrc
```

Install Node.js (ver.LTS):

```bash
nvm install --lts
nvm use --lts
```

Install Javascript Package Manager:

```bash
npm install -g pnpm
```

Check Node.js, pnpm version:

```bash
node -v
pnpm -v
```

Activate local server:

```bash
bash start_local.sh
``` -->